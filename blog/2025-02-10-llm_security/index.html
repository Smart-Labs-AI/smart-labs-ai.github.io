<!doctype html><html lang=en-us><head><meta property="og:url" content="https://smart-labs.ai/blog/2025-02-10-llm_security/"><meta property="og:site_name" content="Smart Labs AI GmbH"><meta property="og:title" content="Gefährliche KI-Modelle"><meta property="og:description" content="Eine Sicherheitslücke in Hugging Face zeigte, wie bösartige Modelle Schwachstellen in Python ausnutzen – was das für die Zukunft der LLM-Sicherheit bedeutet."><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="blog"><meta property="article:published_time" content="2025-02-10T00:00:00+00:00"><meta property="article:modified_time" content="2025-02-10T00:00:00+00:00"><meta name=description content="Eine Sicherheitslücke in Hugging Face zeigte, wie bösartige Modelle Schwachstellen in Python ausnutzen – was das für die Zukunft der LLM-Sicherheit bedeutet."><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta http-equiv=x-ua-compatible content="ie=edge"><title>Smart Labs AI GmbH</title>
<link rel=stylesheet href=/css/googlefonts.min.e934f4ffc3a55e050b414cb5fcea6ccddeca68ef4263fc8142008b085d0b3b97.css integrity="sha256-6TT0/8OlXgULQUy1/Opszd7KaO9CY/yBQgCLCF0LO5c="><link rel=stylesheet type=text/css href=/css/style.min.css><link rel=stylesheet href=/css/fontawesome/6.7.2/css/all.min.css><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest></head><body><div id=preloader><div id=status></div></div><div style=background-color:#00002b;z-index:1><nav class="navbar is-fresh is-transparent no-shadow" role=navigation aria-label="main navigation"><div class=container><div class=navbar-brand><a class=navbar-item href=/ aria-label=home><img src=/images/logos/logo.svg alt=Logo style=max-width:100%;height:auto width=112 height=28>
</a><a role=button class=navbar-burger aria-label=menu aria-expanded=false data-target=navbar-menu><span aria-hidden=true></span>
<span aria-hidden=true></span>
<span aria-hidden=true></span></a></div><div id=navbar-menu class="navbar-menu is-static"><div class=navbar-end><a href=/blog class="navbar-item is-secondary">Blog
</a><a href="https://acc.secphoria.app/realms/arinna/protocol/openid-connect/auth?client_id=labs-ai-landing-page&amp;scope=openid%20profile&amp;redirect_uri=https://acc.secphoria.app&amp;response_type=code" class=navbar-item><span class="button contact-button rounded secondary-btn raised">Sign in
</span></a><a href=/#contact class=navbar-item><span class="button contact-button rounded primary-btn raised">Kontakt</span></a></div></div></div></nav></div><nav id=navbar-clone class="navbar is-fresh is-transparent" role=navigation aria-label="main navigation"><div class=container><div class=navbar-brand><a class=navbar-item href=/ aria-label=home><img src=/images/logos/logo.svg alt=home style=max-width:100%;height:auto width=112 height=28>
</a><a role=button class=navbar-burger aria-label=menu aria-expanded=false data-target=cloned-navbar-menu><span aria-hidden=true></span>
<span aria-hidden=true></span>
<span aria-hidden=true></span></a></div><div id=cloned-navbar-menu class="navbar-menu is-fixed"><div class=navbar-end><a href=/blog class="navbar-item is-secondary">Blog
</a><a href="https://acc.secphoria.app/realms/arinna/protocol/openid-connect/auth?client_id=labs-ai-landing-page&amp;scope=openid%20profile&amp;redirect_uri=https://acc.secphoria.app&amp;response_type=code" class=navbar-item><span class="button contact-button rounded secondary-btn raised">Sign in
</span></a><a href=/#contact class=navbar-item><span class="button contact-button rounded primary-btn raised">Kontakt</span></a></div></div></div></nav><div class="container mx-auto max-w-4xl px-4"><section class="section is-medium"><div class=container><div class=blog-content><div class="columns is-centered"><div class="column is-8 is-centered-tablet-portrait"><div class=has-text-centered><time class=post-date>10. February 2025</time><h1 class="title section-title">Gefährliche KI-Modelle</h1><h5 class="subtitle is-5 is-muted">Eine Sicherheitslücke in Hugging Face zeigte, wie bösartige Modelle Schwachstellen in Python ausnutzen – was das für die Zukunft der LLM-Sicherheit bedeutet.</h5><div class=blog-header><img src=/blog/images/2025-02-10-llm_security_hu4290193563058203238.webp alt="Gefährliche KI-Modelle"></div></div><div class=content><p>Das Feld der Künstlichen Intelligenz, insbesondere großer Sprachmodelle (Large Language Models, LLMs), entwickelt sich rasant weiter. Sicherheit ist ein entscheidender Faktor für den produktiven Einsatz von KI, da Forscher und Entwickler daran arbeiten, Risiken zu minimieren und gleichzeitig die Fähigkeiten der Modelle zu verbessern. Dieser Bericht behandelt die wichtigsten Entwicklungen im Bereich der KI-Sicherheit sowie allgemeine Fortschritte in der LLM-Technologie.</p><h2 id=constitutional-classifiers>Constitutional Classifiers</h2><p>Anthropic hat kürzlich die &ldquo;Constitutional Classifiers&rdquo; eingeführt, einen innovativen Ansatz zur Verbesserung der KI-Sicherheit. Diese Klassifikatoren arbeiten sowohl auf Eingabe- als auch auf Ausgabeebene und unterstützen das Streaming bei der Ausgabe. Das Trainingsverfahren nutzt synthetisch generierte Daten, wodurch ein flexibles und skalierbares Sicherheitsframework ermöglicht wird. Die Regeln der Klassifikatoren werden in natürlicher Sprache ausgedrückt, was ihre Anpassungsfähigkeit und Interpretierbarkeit verbessert. Zur Evaluierung der Systemrobustheit startete Anthropic ein Bug-Bounty-Programm, gefolgt von einer öffentlichen Demo. Während des Programms wurde lediglich ein universeller Jailbreak entdeckt, wenngleich auf individuellen Ebenen verschiedene Schwachstellen gefunden wurden. Ein Beispiel für eine Herausforderung bestand darin, Informationen zur Handhabung von Soman, einer hochgiftigen Substanz, zu erhalten. Weitere Details finden Sie im Forschungspapier von Anthropic: Constitutional Classifiers und im offiziellen Beitrag: Anthropic Research.</p><h2 id=schadhafte-open-source-modelle-auf-hugging-face>Schadhafte Open-Source-Modelle auf Hugging Face</h2><p>Kürzlich wurde eine Sicherheitslücke im Modell-Repository von Hugging Face aufgedeckt. Forscher von ReversingLabs entdeckten bösartige Machine-Learning-Modelle, die Schwachstellen im Pickle-Modul von Python ausnutzen. Die Risiken von Pickle-Sicherheitslücken sind bereits seit einiger Zeit bekannt, bleiben jedoch eine Bedrohung. Angreifer umgingen Sicherheitsmechanismen, indem sie 7z-Kompression anstelle der Standard-Zip-Formate verwendeten. Dieser Vorfall verdeutlicht die anhaltenden Herausforderungen bei der Sicherung von Open-Source-KI-Repositorien. Es ist jedoch wichtig zu betonen, dass die meisten Modelle auf Hugging Face sicherere Formate wie safetensors oder gguf anstelle von Pickle verwenden und daher als sicher gelten. Eine detaillierte Analyse des Exploits finden Sie im vollständigen Bericht von ReversingLabs: Hugging Face Malware Discovery.</p><h2 id=weitere-ki-entwicklungen>Weitere KI-Entwicklungen</h2><p>Spannende Fortschritte gibt es auch im Bereich der grundlegenden KI-Modelle. Berichten zufolge arbeitet OpenAI an GPT-4.5, das intern den Codenamen &ldquo;Onion&rdquo; trägt. Dieses Modell wird das letzte seiner Art sein, das nicht auf &ldquo;Chain-of-Thought&rdquo;-Verarbeitung basiert. Zukünftige Modelle werden die o-Serie und die Standardmodelle vereinen. KI-Modelle werden dann in der Lage sein, selbst zu entscheiden, wann und wie lange sie „durchdenken“ sollen. Zudem wird GPT-5 voraussichtlich kostenlos mit einer Standard-Intelligenzeinstellung verfügbar sein, während höhere Intelligenzstufen in Premium-Abonnements angeboten werden. Lesen Sie die vollständige Ankündigung von Sam Altman.</p><h2 id=während-sie-auf-diese-fortschritte-warten-werfen-sie-einen-blick-auf-den-neuen-hugging-face-agents-course>Während Sie auf diese Fortschritte warten, werfen Sie einen Blick auf den neuen Hugging Face Agents Course.</h2><p>Die Sicherheit in der KI ist eine sich ständig weiterentwickelnde Herausforderung, die kontinuierliche Wachsamkeit und Innovation erfordert. Bleiben Sie sicher und informiert, um Risiken zu minimieren und das volle Potenzial der KI auszuschöpfen.</p></div></div></div></div></div></section></div><footer class="footer footer-dark"><div class=container><div class=columns><div class=column><div class=footer-logo><img src=/images/logos/logo-white.svg loading=lazy alt=Logo></div></div><div class="column is-narrow mr-6"><div class=footer-column><div class=footer-header><h3>Sitemap</h3></div><ul class=link-list><li><a href=/>Start</a></li><li><a href=/blog>Blog</a></li><li><a href=/#contact>Kontakt</a></li></ul></div></div><div class="column is-narrow mr-6"><div class=footer-column><div class=footer-header><h3>Rechtliches</h3></div><ul class=link-list><li><a href=/impressum>Impressum</a></li><li><a href=/datenschutzerklaerung>Datenschutzerklärung</a></li></ul></div></div><div class="column is-flex-grow-1"><div class="footer-column contact"><div class=footer-header><h3>Kontakt</h3><ul class=link-list><li>Südportal 3</li><li>22848 Norderstedt</li><li class=mt-4>+49 40 604 29 83 0</li><li class=mb-4><a href=mailto:kontakt@smart-labs.ai>kontakt@smart-labs.ai</a></li><li><a class=social-media href=https://www.linkedin.com/company/smart-labs-ai-gmbh aria-label=linkedin><span class=icon><i class="fab fa-linkedin"></i></span></a></li></ul></div></div></div></div><div class=columns><div class=column><hr class=divider></div></div><div class="columns last-line"><div class=column>© 2025 Smart Labs AI GmbH – Alle Rechte vorbehalten</div><div class="column is-pulled-right"><div class="is-pulled-right footer-column"><ul class=link-list><li><a href=/impressum>Impressum</a></li><li><a href=/datenschutzerklaerung>Datenschutz</a></li></ul></div></div></div></div></footer><script>window.klaroConfig={version:1,elementID:"klaro",noAutoLoad:!1,htmlTexts:!0,embedded:!1,groupByPurpose:!0,storageMethod:"cookie",cookieName:"klaro",cookieExpiresAfterDays:120,default:!1,mustConsent:!0,acceptAll:!0,hideDeclineAll:!1,hideLearnMore:!1,lang:"de",translations:{de:{privacyPolicyUrl:"/datenschutzerklaerung",consentModal:{title:"Cookie-Einstellungen",description:"Wir verwenden Dienste von Drittanbietern, um unsere Website zu verbessern und dir personalisierte Inhalte anzubieten. Du kannst selbst entscheiden, welche Dienste du zulassen möchtest."},consentNotice:{description:"Wir verwenden Cookies und externe Dienste auf unserer Website. Du kannst selbst entscheiden, welche aktiviert werden sollen.",learnMore:"Anpassen",testing:"Test-Modus!",changeDescription:"Es gab Änderungen an den Diensten seit deinem letzten Besuch, bitte aktualisiere deine Auswahl."},ok:"Akzeptieren",save:"Speichern",decline:"Ablehnen",close:"Schließen",acceptAll:"Alle akzeptieren",acceptSelected:"Auswahl akzeptieren",service:{disableAll:{title:"Alle Dienste an-/ausschalten",description:"Nutze diesen Schalter, um alle Dienste an- oder auszuschalten."}},purposes:{functional:"Funktionale Cookies",analytics:"Statistiken & Analyse",marketing:"Marketing & externe Inhalte",preferences:"Präferenzen"}}},services:[{name:"essential",title:"Essenzielle Dienste",description:"Diese Dienste sind für die Grundfunktionen der Website erforderlich.",purposes:["functional"],required:!0,optOut:!1,onlyOnce:!0},{name:"telemetrydeck",title:"TelemetryDeck",description:"Datenschutzfreundliche Analyse-Software zur Verbesserung unserer Website.",purposes:["analytics"],cookies:[["telemetrydeck-*","/","Speichert anonyme Nutzungsstatistiken"]],required:!1,optOut:!1,onlyOnce:!0,callback:function(e){if(e){if(!window.TelemetryDeck){window.TelemetryDeck=window.TelemetryDeck||{};var n=document.createElement("script");n.src="https://cdn.telemetrydeck.com/websdk/telemetrydeck.min.js",n.setAttribute("data-app-id","CD9FC7F8-AC75-4B5E-8EB9-5B60AE3CAC4E"),n.async=!0,document.head.appendChild(n)}}else window.TelemetryDeck&&window.TelemetryDeck.disable&&window.TelemetryDeck.disable()}},{name:"pipedrive-chat",title:"Pipedrive Chat",description:"Live-Chat-Widget für Kundenbetreuung und Support.",purposes:["marketing"],cookies:[["_pipedriveLeadbooster*","/","Pipedrive Chat-Funktionalität"],["leadbooster*",".pipedrive.com","Chat-Sitzungsdaten"]],required:!1,optOut:!1,onlyOnce:!0,callback:function(e){if(e){if(!window.pipedriveLeadboosterConfig){window.pipedriveLeadboosterConfig={base:"leadbooster-chat.pipedrive.com",companyId:13886412,playbookUuid:"10fd1b0a-bfe0-4733-8970-d52b00fcd920",version:2},function(){var e=window;if(e.LeadBooster){console.warn("LeadBooster already exists");return}e.LeadBooster={q:[],on:function(e,t){this.q.push({t:"o",n:e,h:t})},trigger:function(e){this.q.push({t:"t",n:e})}}}();var s,n=document.createElement("script");n.src="https://leadbooster-chat.pipedrive.com/assets/loader.js",n.async=!0,document.body.appendChild(n)}}else s=document.querySelectorAll('[id*="leadbooster"], [class*="leadbooster"]'),s.forEach(function(e){e.remove()})}},{name:"pipedrive-form",title:"Pipedrive Webformular",description:"Kontaktformular via Pipedrive.",purposes:["marketing"],required:!1,callback:function(e){const n=document.getElementById("pipedrive-form-placeholder");if(e&&n){var s=document.createElement("script");s.src="https://webforms.pipedrive.com/f/loader",s.async=!0,document.body.appendChild(s),n.style.display="none"}else n&&(n.innerHTML="<h2>Um dieses Formular zu sehen, akzeptiere bitte Marketing-Cookies.</h2>",n.style.display="block")}}]}</script><script src=/js/klaro-v0.7.js></script><script src=/js/jquery-3.7.1.min.js></script><script src=/js/modernizr-custom.js></script><script src=/js/fresh.js></script><script src=/js/jquery.panelslider.min.js></script></body></html>