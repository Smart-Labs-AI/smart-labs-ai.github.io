<!doctype html><html lang=en-us><head><meta property="og:url" content="https://smart-labs.ai/blog/2025-02-01-agents_secure/"><meta property="og:site_name" content="Smart Labs AI GmbH"><meta property="og:title" content="Sind KI-Agenten sicher?"><meta property="og:description" content="LLMs und KI-Agenten sind anfällig für Manipulationen, weshalb robuste Sicherheitsmaßnahmen, kontinuierliche Überwachung und die Einhaltung neuer regulatorischer Anforderungen wie dem EU AI Act entscheidend sind."><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="blog"><meta property="article:published_time" content="2025-02-01T00:00:00+00:00"><meta property="article:modified_time" content="2025-02-01T00:00:00+00:00"><meta name=description content="LLMs und KI-Agenten sind anfällig für Manipulationen, weshalb robuste Sicherheitsmaßnahmen, kontinuierliche Überwachung und die Einhaltung neuer regulatorischer Anforderungen wie dem EU AI Act entscheidend sind."><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta http-equiv=x-ua-compatible content="ie=edge"><title>Smart Labs AI GmbH</title>
<link rel=stylesheet href=/css/googlefonts.min.e934f4ffc3a55e050b414cb5fcea6ccddeca68ef4263fc8142008b085d0b3b97.css integrity="sha256-6TT0/8OlXgULQUy1/Opszd7KaO9CY/yBQgCLCF0LO5c="><link rel=stylesheet type=text/css href=/css/style.min.css><link rel=stylesheet href=/css/fontawesome/6.7.2/css/all.min.css><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest></head><body><div id=preloader><div id=status></div></div><div style=background-color:#00002b;z-index:1><nav class="navbar is-fresh is-transparent no-shadow" role=navigation aria-label="main navigation"><div class=container><div class=navbar-brand><a class=navbar-item href=/ aria-label=home><img src=/images/logos/logo.svg alt=Logo style=max-width:100%;height:auto width=112 height=28>
</a><a role=button class=navbar-burger aria-label=menu aria-expanded=false data-target=navbar-menu><span aria-hidden=true></span>
<span aria-hidden=true></span>
<span aria-hidden=true></span></a></div><div id=navbar-menu class="navbar-menu is-static"><div class=navbar-end><a href=/blog class="navbar-item is-secondary">Blog
</a><a href="https://acc.secphoria.app/realms/arinna/protocol/openid-connect/auth?client_id=labs-ai-landing-page&amp;scope=openid%20profile&amp;redirect_uri=https://acc.secphoria.app&amp;response_type=code" class=navbar-item><span class="button contact-button rounded secondary-btn raised">Sign in
</span></a><a href=/#contact class=navbar-item><span class="button contact-button rounded primary-btn raised">Kontakt</span></a></div></div></div></nav></div><nav id=navbar-clone class="navbar is-fresh is-transparent" role=navigation aria-label="main navigation"><div class=container><div class=navbar-brand><a class=navbar-item href=/ aria-label=home><img src=/images/logos/logo.svg alt=home style=max-width:100%;height:auto width=112 height=28>
</a><a role=button class=navbar-burger aria-label=menu aria-expanded=false data-target=cloned-navbar-menu><span aria-hidden=true></span>
<span aria-hidden=true></span>
<span aria-hidden=true></span></a></div><div id=cloned-navbar-menu class="navbar-menu is-fixed"><div class=navbar-end><a href=/blog class="navbar-item is-secondary">Blog
</a><a href="https://acc.secphoria.app/realms/arinna/protocol/openid-connect/auth?client_id=labs-ai-landing-page&amp;scope=openid%20profile&amp;redirect_uri=https://acc.secphoria.app&amp;response_type=code" class=navbar-item><span class="button contact-button rounded secondary-btn raised">Sign in
</span></a><a href=/#contact class=navbar-item><span class="button contact-button rounded primary-btn raised">Kontakt</span></a></div></div></div></nav><div class="container mx-auto max-w-4xl px-4"><section class="section is-medium"><div class=container><div class=blog-content><div class="columns is-centered"><div class="column is-8 is-centered-tablet-portrait"><div class=has-text-centered><time class=post-date>01. February 2025</time><h1 class="title section-title">Sind KI-Agenten sicher?</h1><h5 class="subtitle is-5 is-muted">LLMs und KI-Agenten sind anfällig für Manipulationen, weshalb robuste Sicherheitsmaßnahmen, kontinuierliche Überwachung und die Einhaltung neuer regulatorischer Anforderungen wie dem EU AI Act entscheidend sind.</h5><div class=blog-header><img src=/blog/images/2025-02-01-agents_secure_hu607399202483762749.webp alt="Sind KI-Agenten sicher?"></div></div><div class=content><p>Große Sprachmodelle (LLMs) sind nicht von Natur aus sicher. Die von ihnen ausgehenden Risiken beschränken sich nicht nur auf Halluzinationen oder fehlerhafte Ausgaben – LLMs können manipuliert werden. Traditionelle Sicherheitsmaßnahmen wie Inhaltsfilterung und Zugriffskontrolle haben sich als nicht robust genug erwiesen, um Angriffe zu verhindern. Beispielsweise können „Jailbreak“-Techniken genutzt werden, um Einschränkungen zu umgehen und ein LLM dazu zu bringen, Aktionen auszuführen, die es eigentlich vermeiden sollte.</p><p>Doch was passiert, wenn ein LLM mit einem KI-Agenten verbunden wird, der über die reine Textgenerierung hinaus Aufgaben ausführen kann – wie das Versenden von E-Mails, das Ausführen von Code oder das Bearbeiten von Dokumenten? Dies führt zu einer völlig neuen Dimension von Sicherheitsbedenken. Wenn das zugrunde liegende Modell selbst verwundbar ist, wie kann dann ein darauf aufbauender KI-Agent sicher sein?</p><h2 id=untersuchung-der-sicherheit-von-ki-agenten>Untersuchung der Sicherheit von KI-Agenten</h2><p>Die Herausforderung bei der Sicherung von KI-Agenten besteht darin, unbefugte oder unbeabsichtigte Aktionen zu verhindern. Ein herausragendes Beispiel für dieses Problem zeigt sich in der aktuellen Sicherheitsforschung zur KI-gesteuerten Aufgabenausführung. Insbesondere konzentrieren sich aktuelle Angriffe darauf, ob ein KI-Agent dazu gebracht werden kann, Aufgaben auszuführen, für die er nie vorgesehen war.</p><p>Ein Beispiel hierfür ist der Wettbewerb „Adaptive Prompt Injection: LLMail Inject“, der die Risiken einer unbefugten E-Mail-Komposition und -Übertragung aufzeigt. In diesem Szenario wird untersucht, ob ein Angreifer subtil Einfluss auf einen KI-Agenten nehmen kann, sodass dieser eine E-Mail mit bestimmten Inhalten versendet – obwohl der Benutzer lediglich eine Zusammenfassung angefordert hat. Solche Sicherheitslücken verdeutlichen die Notwendigkeit robuster Abwehrmaßnahmen.</p><h2 id=abwehrmechanismen-in-modernen-ki-systemen>Abwehrmechanismen in modernen KI-Systemen</h2><p>Um diese Risiken zu minimieren, wurden mehrere Sicherheitsschichten vorgeschlagen und implementiert, darunter:</p><ul><li><strong>LLM-Judges:</strong> Mechanismen, die Ausgaben auf Richtlinienverstöße prüfen, bevor sie ausgeführt werden.</li><li><strong>Task-Drift-Überwachung:</strong> Systeme, die erkennen, wenn ein KI-Agent von seiner vorgesehenen Funktion abweicht.</li><li><strong>Prompt Shields:</strong> Techniken zur Bereinigung und Filterung von Eingabeaufforderungen, um manipulative Angriffe zu verhindern.</li><li><strong>Spotlighting und Instruktionshierarchie:</strong> Strategien, die strukturierte und kontextbewusste Interaktionen erzwingen, um potenzielle Angriffe zu begrenzen.</li></ul><p>Diese Methoden werden in cloudbasierten Umgebungen wie Azure AI eingesetzt, können jedoch auch in On-Premises-Lösungen unter Verwendung von Open-Source-Technologien implementiert werden. Dennoch bietet keine dieser Ansätze einen vollständigen Schutz, sodass kontinuierliche Bewertung und Verbesserung entscheidend sind.</p><h2 id=compliance-und-zukünftige-auswirkungen>Compliance und zukünftige Auswirkungen</h2><p>Ab August 2025 wird der EU AI Act die Implementierung modernster Sicherheitsmaßnahmen für allgemeine KI-Systeme, einschließlich LLMs, vorschreiben. Diese Regulierung unterstreicht die Dringlichkeit, KI-Agenten gegen neue Bedrohungen abzusichern.</p><p>Angesichts dieser Entwicklungen müssen Unternehmen und Forschende ihre KI-gestützten Workflows gründlich evaluieren, um festzustellen, ob ihre Agenten wirklich sicher sind. Die entscheidende Frage bleibt: <strong>Ist Ihr KI-Agent wirklich sicher?</strong> Die Antwort erfordert kontinuierliches Testen, Überwachen und Anpassen von Sicherheitsmaßnahmen, um sich gegen sich entwickelnde Bedrohungen zu wappnen.</p></div></div></div></div></div></section></div><footer class="footer footer-dark"><div class=container><div class=columns><div class=column><div class=footer-logo><img src=/images/logos/logo-white.svg loading=lazy alt=Logo></div></div><div class="column is-narrow mr-6"><div class=footer-column><div class=footer-header><h3>Sitemap</h3></div><ul class=link-list><li><a href=/>Start</a></li><li><a href=/blog>Blog</a></li><li><a href=/#contact>Kontakt</a></li></ul></div></div><div class="column is-narrow mr-6"><div class=footer-column><div class=footer-header><h3>Rechtliches</h3></div><ul class=link-list><li><a href=/impressum>Impressum</a></li><li><a href=/datenschutzerklaerung>Datenschutzerklärung</a></li></ul></div></div><div class="column is-flex-grow-1"><div class="footer-column contact"><div class=footer-header><h3>Kontakt</h3><ul class=link-list><li>Südportal 3</li><li>22848 Norderstedt</li><li class=mt-4>+49 40 604 29 83 0</li><li class=mb-4><a href=mailto:kontakt@smart-labs.ai>kontakt@smart-labs.ai</a></li><li><a class=social-media href=https://www.linkedin.com/company/smart-labs-ai-gmbh aria-label=linkedin><span class=icon><i class="fab fa-linkedin"></i></span></a></li></ul></div></div></div></div><div class=columns><div class=column><hr class=divider></div></div><div class="columns last-line"><div class=column>© 2025 Smart Labs AI GmbH – Alle Rechte vorbehalten</div><div class="column is-pulled-right"><div class="is-pulled-right footer-column"><ul class=link-list><li><a href=/impressum>Impressum</a></li><li><a href=/datenschutzerklaerung>Datenschutz</a></li></ul></div></div></div></div></footer><script>window.klaroConfig={version:1,elementID:"klaro",noAutoLoad:!1,htmlTexts:!0,embedded:!1,groupByPurpose:!0,storageMethod:"cookie",cookieName:"klaro",cookieExpiresAfterDays:120,default:!1,mustConsent:!0,acceptAll:!0,hideDeclineAll:!1,hideLearnMore:!1,lang:"de",translations:{de:{privacyPolicyUrl:"/datenschutzerklaerung",consentModal:{title:"Cookie-Einstellungen",description:"Wir verwenden Dienste von Drittanbietern, um unsere Website zu verbessern und dir personalisierte Inhalte anzubieten. Du kannst selbst entscheiden, welche Dienste du zulassen möchtest."},consentNotice:{description:"Wir verwenden Cookies und externe Dienste auf unserer Website. Du kannst selbst entscheiden, welche aktiviert werden sollen.",learnMore:"Anpassen",testing:"Test-Modus!",changeDescription:"Es gab Änderungen an den Diensten seit deinem letzten Besuch, bitte aktualisiere deine Auswahl."},ok:"Akzeptieren",save:"Speichern",decline:"Ablehnen",close:"Schließen",acceptAll:"Alle akzeptieren",acceptSelected:"Auswahl akzeptieren",service:{disableAll:{title:"Alle Dienste an-/ausschalten",description:"Nutze diesen Schalter, um alle Dienste an- oder auszuschalten."}},purposes:{functional:"Funktionale Cookies",analytics:"Statistiken & Analyse",marketing:"Marketing & externe Inhalte",preferences:"Präferenzen"}}},services:[{name:"essential",title:"Essenzielle Dienste",description:"Diese Dienste sind für die Grundfunktionen der Website erforderlich.",purposes:["functional"],required:!0,optOut:!1,onlyOnce:!0},{name:"telemetrydeck",title:"TelemetryDeck",description:"Datenschutzfreundliche Analyse-Software zur Verbesserung unserer Website.",purposes:["analytics"],cookies:[["telemetrydeck-*","/","Speichert anonyme Nutzungsstatistiken"]],required:!1,optOut:!1,onlyOnce:!0,callback:function(e){if(e){if(!window.TelemetryDeck){window.TelemetryDeck=window.TelemetryDeck||{};var n=document.createElement("script");n.src="https://cdn.telemetrydeck.com/websdk/telemetrydeck.min.js",n.setAttribute("data-app-id","CD9FC7F8-AC75-4B5E-8EB9-5B60AE3CAC4E"),n.async=!0,document.head.appendChild(n)}}else window.TelemetryDeck&&window.TelemetryDeck.disable&&window.TelemetryDeck.disable()}},{name:"pipedrive-chat",title:"Pipedrive Chat",description:"Live-Chat-Widget für Kundenbetreuung und Support.",purposes:["marketing"],cookies:[["_pipedriveLeadbooster*","/","Pipedrive Chat-Funktionalität"],["leadbooster*",".pipedrive.com","Chat-Sitzungsdaten"]],required:!1,optOut:!1,onlyOnce:!0,callback:function(e){if(e){if(!window.pipedriveLeadboosterConfig){window.pipedriveLeadboosterConfig={base:"leadbooster-chat.pipedrive.com",companyId:13886412,playbookUuid:"10fd1b0a-bfe0-4733-8970-d52b00fcd920",version:2},function(){var e=window;if(e.LeadBooster){console.warn("LeadBooster already exists");return}e.LeadBooster={q:[],on:function(e,t){this.q.push({t:"o",n:e,h:t})},trigger:function(e){this.q.push({t:"t",n:e})}}}();var s,n=document.createElement("script");n.src="https://leadbooster-chat.pipedrive.com/assets/loader.js",n.async=!0,document.body.appendChild(n)}}else s=document.querySelectorAll('[id*="leadbooster"], [class*="leadbooster"]'),s.forEach(function(e){e.remove()})}},{name:"pipedrive-form",title:"Pipedrive Webformular",description:"Kontaktformular via Pipedrive.",purposes:["marketing"],required:!1,callback:function(e){const n=document.getElementById("pipedrive-form-placeholder");if(e&&n){var s=document.createElement("script");s.src="https://webforms.pipedrive.com/f/loader",s.async=!0,document.body.appendChild(s),n.style.display="none"}else n&&(n.innerHTML="<h2>Um dieses Formular zu sehen, akzeptiere bitte Marketing-Cookies.</h2>",n.style.display="block")}}]}</script><script src=/js/klaro-v0.7.js></script><script src=/js/jquery-3.7.1.min.js></script><script src=/js/modernizr-custom.js></script><script src=/js/fresh.js></script><script src=/js/jquery.panelslider.min.js></script></body></html>