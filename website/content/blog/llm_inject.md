---
title: "Wenn KI-Agenten unsere Mails verwalten: Wie sicher ist das?"
date: 2025-04-09
layout: "blog"
image: "/blog/images/llm_inject.webp"
summary: "Im spannenden Interview mit dem SCY Club-Team, das beim IEEE SaTML 2025 LLMail-Inject-Wettbewerb den 11. Platz unter 224 Teams erreichte, erfahren Sie aus erster Hand, wie verwundbar selbst Microsofts modernste KI-Sicherheitssysteme sind."
---

Das Team aus erfahrenen Security-Experten und KI-Spezialisten von Smart Labs AI und Smart Cyber Security gibt Einblick in die faszinierende Welt der KI-Sicherheit:

üîç Wie man mit Tricks wie "Capitalization" und "Best-of-N tailbreaking" modernste KI-Schutzsysteme umgehen kann
üö® Warum Unternehmen ihren KI-Agenten oft zu viele Berechtigungen einr√§umen
‚öîÔ∏è Das nie endende Katz-und-Maus-Spiel zwischen Angreifern und Verteidigern im KI-Sicherheitsbereich
üîÆ Was die Zukunft f√ºr autonome KI-Systeme und deren Sicherheit bringt

**Dennis Rall:** arbeitet bei Smart Labs AI als AI Engineer und AI Researcher. Er besch√§ftigt sich mit Schwachstellen von Large Language Models (LLMs) und wie man diese sicher in bestehende IT-Landschaften integrieren kann und macht gerade seinen Dr. an der Universit√§t AUgsburg. Der LLMail-Inject-Wettbewerb war sein erster CTF-Wettbewerb.[LinkedIn] (https://www.linkedin.com/in/dennis-rall/)
  
**Dr. Thomas Fraunholz** ist ein engagierter Wissenschaftler mit Schwerpunkt in angewandter Mathematik. Nach seiner Promotion entdeckte er in der Embedded-Programmierung und DevOps seine Leidenschaft, was ihn zum anerkannten MLOps- und NLP-Experten machte. Er leitete bereits zwei √∂ffentlich gef√∂rderte Open-Source-Forschungsprogramme im Bereich KI in Kooperation mit dem Deutschen Zentrum f√ºr Luft- und Raumfahrt. Heute steht er an der Spitze der KI-basierten Cybersecurity-Forschung als Senior Reseracher bei der Smart Labs AI.[LinkedIn] (https://www.linkedin.com/in/thomas-fraunholz/)

**Sandro Bauer** ist CTF Spieler und Pentester. Besch√§ftigt sich seit 2018 mit dem Thema Security und hat endlose Wochenenden in CTFs versenkt und hat sein Hobby nach dem Studium zum Beruf gemacht. [Website](https://sandr0.xyz)

**Florian Ludwig** ist Sinologe, Data Scientist und technischer Vertriebler. Besch√§ftigt sich seit 2019 vertieft mit AI und Digitalisierung. Seit er auf Smart-Labs AI gesto√üen ist, hat Sicherheit einen komplett neuen Stellenwert bekommen. [LinkedIn](https://www.linkedin.com/in/florian-p-ludwig/)

## Vorstellung des Teams

**Smart Labs AI:** Herzlich willkommen zum Interview √ºber den spannenden LLMail-Inject-Wettbewerb im Rahmen der 3rd IEEE Conference on Secure and Trustworthy Machine Learning (SaTML) 2025! Ich freue mich, heute das Team ‚ÄûSCY Club‚Äú begr√º√üen zu d√ºrfen. Stellt euch doch bitte kurz vor.

**Dennis Rall:** Hallo! Ich bin Dennis Rall und es ist mein erster CTF (Capture the Flag) Wettbewerb gewesen. Ich arbeite bei smart Labs Ai als einer Mischung von Ai Engineer und Ai Researcher. Wir besch√§ftigen uns mit Schwachstellen von Large Language Models (LLMs) insbesondere wie man diese sicher in bestehende IT-Landschaften integriert.

**Dr. Thomas Fraunholz:** Genau, mein Name ist Thomas Fraunholz, ich bin Senior Researcher bei der Smart Labs AI und besch√§ftige mich wie Dennis in einem Team mit den Schwachstellen von LLMs. Der aktuelle Wettkampf war mein zweiter CTF nach dem Letztj√§hrigen, in dem ebenfalls Sandro schon mit dabei war. Letztes Jahr hatten wir schon viel Spa√ü gemeinsam und es war wieder eine super Geschichte mitzumachen, aber da werden wir sicher gleich mehr dr√ºber reden.

**Sandro Bauer:** Ich bin Sandro Bauer und arbeite bei Smart Cyber Security, der Zwillingsfirma von Smart Labs AI. Ich nehme seit 2019 regelm√§√üig an CTFs teil, allerdings eher im klassischen Security-Bereich. Da geht es typischerweise darum, Webserver zu hacken, Zugriff auf Admin-Accounts zu bekommen oder Server zu kompromittieren. Im Gegensatz zu meinen Kollegen bin ich im CTF-Bereich der Erfahrenste, aber im AI-Bereich sehr neu. Letztes Jahr haben Thomas und ich bei einem AI CTF gut harmoniert - ich habe Security-Knowledge eingebracht, w√§hrend Thomas die AI-Expertise hatte. Bei diesem aktuellen LLMail-Inject-Wettbewerb war ich leider weniger beteiligt, da ich parallel einen eigenen ‚Äúklassischen‚Äù CTF mitorganisiert habe.

**Smart Labs AI:** K√∂nnt ihr uns kurz erkl√§ren, worum es bei LLMail-Inject eigentlich ging?

**Dr. Thomas Fraunholz:** Beim aktuellen Wettkampf LLMail Inject ging es darum, dass Microsoft zusammen mit der ETH Z√ºrich wissen wollte, wie sicher eigentlich KI-Agenten sind. Dabei hat - wohl mit Hintergedanken - nat√ºrlich die Verteidigungsmechanismen ihrer Cloud zur Verf√ºgung auf die Probe gestellt. Dabei sind auch aktuelle Modelle von OpenAI und Microsoft zur Verf√ºgung gestellt worden. Hab ich was vergessen Dennis?

**Dennis Rall:** Man k√∂nnte vielleicht erw√§hnen, dass der letztj√§hrige CTF sich mit allen LLMs besch√§ftigt hat, um diese zu knacken. Der diesj√§hrige CTF war einen Schritt weiter und hat sich mit einem KI-Agenten System f√ºr Mails besch√§ftigt. In diesem Mail-Szenario hat der KI-Agent Zugriff auf Mails, kann Mails lesen und Mails schreiben. Unser Ziel als Attacker war es eine b√∂sartige Mail zusammenzuschreiben, die wir dann in dieses System reinbringen. Wir wollen damit den KI-Agenten dazu bringen, uns Informationen zur√ºckzugeben, die er uns dann per Mail schickt.

**Sandro Bauer:** Hier ging es um einen realit√§tsnahen KI-Agenten mit verschiedenen Verteidigungsmechanismen. Wir haben praktisch getestet, wie robust diese Sicherheitsma√ünahmen gegen Prompt-Injection sind. F√ºr Microsoft war es wertvolle Forschung, f√ºr uns eine Chance, praxisnahe Schwachstellen zu verstehen. Kritisch sehe ich, dass viele Unternehmen LLMs mit zu weitreichenden Berechtigungen einsetzen, ohne die Risiken richtig zu durchdenken.

**Smart Labs AI:** Interessant! Wie lange hat man denn Zeit, bzw. wie lange dauert ein solcher Wettbewerb?

**Dr. Thomas Fraunholz:** Sandro meinte CTFs k√∂nnen sehr kurz sein ‚Äì manchmal nur wenige Stunden. Dieser dauerte deutlich l√§nger. Insgesamt sogar mehrere Wochen, genau wie beim letztj√§hrigen. Dies bildet auch die Komplexit√§t der Aufgabe ab. Wir hatten f√ºr die einzelnen Problemstellungen ungef√§hr einen Monat Zeit, in der wir die L√∂sungen eingeben konnten.

**Smart Labs AI::** Danke, nun kommen wir zu einer f√ºr mich pers√∂nlich sehr wesentlichen Frage: Was hat euch motiviert, an diesem Wettbewerb teilzunehmen?

**Dr. Thomas Fraunholz:** Ich bin gespannt darauf, was Dennis berichten wird, da er zum ersten Mal dabei ist. Als ich das letzte Mal in einen CTF hineingeworfen wurde, h√§tte ich nie gedacht, dass die Lernkurve so steil sein w√ºrde. Der spielerische Ansatz ‚Äì in einem Wettbewerb darum zu k√§mpfen, besser als die anderen Teams zu sein ‚Äì entfacht eine enorme Motivation, die zu einer rasanten Lernkurve in k√ºrzester Zeit f√ºhrt. Das finde ich besonders spannend, um sich intensiv mit neuen Themen auseinanderzusetzen.

**Dennis Rall:** Es ist doch immer eine M√∂glichkeit, sein theoretisches Wissen, was wir uns vorher auch angeeignet haben, quasi die Praxis umzusetzen und dann eben auch zu sehen, wie schneidet man den Vergleich mit den anderen Teams ab.

**Sandro Bauer:** Bei mir ist es schwer zu erkl√§ren - es ist einfach intrinsische Motivation. Ich habe einfach Lust darauf. Das ist meiner Meinung nach das Wichtigste, was man als Security Researcher braucht: den eigenen Antrieb, Dinge verstehen und "kaputt machen" zu wollen. Mir geht es darum, Technologie nicht nur zu benutzen, sondern wirklich zu durchdringen. Und dieser "Endorphin-Rush" nach stundenlanger Frustration, wenn man endlich die L√∂sung findet, ist unbeschreiblich. Mein gesamtes Security-Wissen habe ich durch CTFs erworben - durch praktisches Ausprobieren, Scheitern, Lernen und letztendlich doch Erfolg haben.

**Smart Labs AI::** Wie es denn gelaufen?

**Dr. Thomas Fraunholz:** Ja, das erschreckende Ergebnis ist, dass die aktuellen Sicherheitsmechanismen der Microsoft Cloud nicht das halten, was man sich eigentlich versprechen w√ºrde, und zwar: Sichere KI-Agenten. Dennis, w√ºrdest du mir da zustimmen?

**Dennis Rall:** Auf jeden Fall. Am Ende haben wir den elften Platz belegt, wobei wir sogar mehr Szenarios gel√∂st haben als der zehnte Platz. Aber durch das Scoring vom CTF wurden die Level ein bisschen unterschiedlich gewertet, je nachdem wie viele andere Teams ein Level gel√∂st haben und wer das Level zuerst gel√∂st hat. Deswegen sind wir nach diesem Scoring Elfter, nach gel√∂sten Levels w√§ren wir sogar Neunter. Aber es ist auf jeden Fall ein Ergebnis, mit dem ich sehr, sehr zufrieden bin und gezeigt habe, dass wir da auch mit den Top-Teams mithalten k√∂nnen. Platz 11 von 224 Teams kann sich sehen lassen.

**Smart Labs AI:** Wie sieht das denn im Arbeitsalltag aus? Gibt es M√∂glichkeiten, feste Fokus-Blocks zu integrieren, bei denen Ihr an solchen Wettbewerben teilnehmen k√∂nnt?

**Dr. Thomas Fraunholz:** Dankenswerterweise haben wir mit Benjamin auch einen Gesch√§ftsf√ºhrer, der aus seiner eigenen Historie heraus die Teilnahme an CTFs sehr stark unter den Mitarbeitern promotet und unterst√ºtzt. Wir durften in der Tat in unserer Arbeitszeit diesen Wettbewerb durchf√ºhren. Aber wie gesagt, die Lernkurve ist ja wirklich extrem hoch und deswegen gibt es auch der Smart Labs AI wiederum Wissen zur√ºck, die wir dann f√ºr unsere Kunden einsetzen k√∂nnen.

**Dennis Rall:** Es war auch so, dass man pro Minute nur eine L√∂sung senden konnte. Das hei√üt, wir haben es auch oft so gemacht, dass wir ein paar Ideen gesammelt haben. Die haben wir dann laufen lassen. Es hat dann einige Zeit gedauert. In dieser Zeit konnten wir uns dann mit etwas anderem besch√§ftigen und neue Ideen sammeln. Gesamt haben wir versucht dieses Limit gut auszusch√∂pfen und konsequent kontinuierlich anzugreifen.

**Smart Labs AI:** Ich finde es toll, dass Ihr so stark unterst√ºtzt werdet und dass es so stark promotet wird. Um es noch greifbarer zu machen. Wie viel Arbeitszeit ‚Äì wahrscheinlich ja flexibel ausgelegt - steht euch f√ºr solche Wettbewerbe zur Verf√ºgung?

**Dr. Thomas Fraunholz:** Ich w√ºrde sagen, in der Hochphase, also wo es dann wirklich hoch her ging, konnte man wirklich ‚Äûall in‚Äú gehen, so dass wir dann mal eine ganze Woche Zeit investiert haben, wo wir uns kontinuierlich auch Gedanken dar√ºber gemacht haben. Und dann gab es nat√ºrlich auch Zeiten, in denen man gesagt hat, wir lassen jetzt einfach mal unsere automatisierten Attacken so nebenher laufen.

**Sandro Bauer:** Durch unseren Chef Ben wird das tats√§chlich stark gef√∂rdert. Beim letzten CTF hatten Thomas und ich sogar zwei Wochen bekommen, um uns voll darauf zu konzentrieren. Wir haben nat√ºrlich auch an den Wochenenden au√üerhalb der Arbeitszeit weitergemacht. Das hat sich richtig ausgezahlt - wir sind dann nach Amsterdam gefahren und haben unsere Ergebnisse vorgestellt. Falls man dazu mehr lernen m√∂chte kann man auch ein Youtube video ansehen.

[Anm. d. Red.: Das Video ist hier [hier](https://www.youtube.com/watch?v=q1fOrxYXbmk) zu sehen]

CTFs sind aber nicht nur reine Arbeitszeit - manchmal sitzt man abends oder am Wochenende noch dran, weil man einfach nicht aufh√∂ren kann, wenn man kurz vor dem Durchbruch steht. Im diesj√§hrigen CTF hatte ich aber einen eigenen mitorganisieren m√ºssen und konnte daher nur teilweise hier mitwirken, der Hauptanteil des Erfolgs geht also an meine Teamkollegen.

**Smart Labs AI:** Gut, dann m√∂chte ich inhaltlich einige Fragen stellen ‚Äì vor allem: Was waren die beeindruckendsten Aha-Momente oder Erfolgsmomente bei diesem Wettbewerb?

**Dennis Rall:** Zun√§chst einmal: Der CTF war so konzipiert, dass er stets verschiedene Szenarien bot, in denen unterschiedliche Modelle zum Einsatz kamen ‚Äì einmal das Phi3-Modell, ein anderes Mal GPT4o-mini. Mit GPT4o-mini hatten wir eine Zeit lang intensiv zu k√§mpfen, da bereits im Training eine Verteidigungsma√ünahme namens Instruction Hierarchy implementiert war. Als wir es schlie√ülich nach einiger Zeit intensiven Ausprobierens schafften, diese zu √ºberwinden und die Level mit GPT4o-mini zu l√∂sen, erlebten wir einen echten Erfolgs-Moment.

## Verteidigungsmethoden ‚Äì einfaches Beispiel, wie man sie umgehen kann

**Smart Labs AI:** K√∂nnt Ihr ein typisches Beispiel geben, wie man ein Model √ºberlisten kann? Am besten ein einfaches, dass auch ‚Äûold School‚Äú sein kann, damit man sich das ein wenig vorstellen kann?

**Dr. Thomas Fraunholz:** Ich glaube, die Capitalization, Dennis, kann man ganz gut erkl√§ren, oder?

**Dennis Rall:** Ja. Im Prinzip gibt es eine Strategie f√ºr Attacken, die hei√üt Best-of-N tailbreaking. Die funktioniert so, dass ich einen Prompt habe und da eben zuf√§llig Kleinbuchstaben in den Gro√übuchstaben umwandle, Das hat dann die Auswirkung, dass die Tokens, in die die W√∂rter zerlegt werden, bevor sie zum LLM reingegeben werden, dass die sich leicht √§ndern, aber eben der Inhalt noch m√∂glichst nah an dem urspr√ºnglichen Input bleibt und man dadurch durchaus auch Sicherheitsmechanismen umgehen kann. Das ist auch eine Technik, die wir dann auch sehr, sehr oft und auch erfolgreich eingesetzt haben.

## Blick in die Zukunft

**Smart Labs AI:** Danke f√ºr die Einsicht. Wer tiefer gehen m√∂chte: [YouTube Video](https://www.youtube.com/watch?v=pTSKL6e66mE) Nun ein Blick in die Zukunft: Welche Entwicklungen seht ihr in der KI-Security auf uns zukommen? Werden die Systeme sicherer?

**Dr. Thomas Fraunholz:** Hoffentlich.

**Dennis Rall:** Es ist ein typisches Katz-und-Maus-Spiel, wie es auch so bei klassischem Hacking im Prinzip der Fall ist. Das hei√üt, die Attacken entwickeln sich, dann werden die Verteidigungen wieder angepasst.
Das sieht man jetzt auch daran, dass der CTF in die zweite Runde geht, wo sich Microsoft auch angeschaut hat, wie sind denn die Angeleiter durch die Sicherheitsschranken durchgegangen und haben ein bisschen Fine-Tuning an ihren Verteidigungen betrieben und dann in die zweite Runde gestartet. Allerdings wurden da auch schon wieder die ersten Verteidigungen umgangen.
Das hei√üt, man sollte weiterhin auch immer, wenn man KI-Systeme einsetzt, sich der Risiken Bewusstsein und auch immer an die Sicherheitsmechanismen denken.

**Smart Labs AI:** Danke, Herr Dr. Fraunholz, haben Sie auch noch eine Idee?

**Dr. Thomas Fraunholz:** Ich glaube, man sollte grunds√§tzlich das Prinzip der walten lassen, das auch in anderen Bereichen gilt: nur immer so viel Information wie unbedingt f√ºr die Aufgabe notwendig, einem KI-System zur Verf√ºgung zu stellen. Und auch nicht zu viel Autonomie erwarten oder fordern. Ich glaube, dann ist man eigentlich recht gut aufgestellt.

**Dennis Rall:** Wir m√ºssen dazu bedenken, dass sich die KI in Richtung gr√∂√üerer Selbstst√§ndigkeit entwickelt ‚Äì sie ‚Äûnavigiert‚Äú beispielsweise zunehmend autonom durch den Browser. Manus war dazu vor einigen Wochen in den Medien, und nat√ºrlich werden, je mehr die KI eigenst√§ndig agiert ‚Äì etwa bei automatisierten Reiseplanungen ‚Äì auch weitere Sicherheitsregeln erforderlich. Auch internationale Grenzen werden
Wobei tats√§chlich da ja auch gerade so ein bisschen viel sich in die Richtung entwickelt, dass so der KI auch quasi sich durch den Browser durchfliegt. Ich glaube, da war es Manus vor ein paar Wochen auch hoch in den Medien. Und nat√ºrlich, je mehr die KI selbstst√§ndig macht, wenn es dann auch in Richtung irgendwie automatisch meine Reise in andere L√§nder geht, da kommen nat√ºrlich noch mal viel mehr Sicherheitsregeln auf uns zu. Und nat√ºrlich sollte noch mehr Fokus auf die Sicherheit gelegt werden.

**Sandro Bauer:** Ich stimme Thomas absolut zu - weniger ist definitiv mehr bei KI-Systemen! Als Industrie befinden wir uns gerade in einer gef√§hrlichen Phase, wo wir √ºberall KI einsetzen wollen, ohne die Sicherheitsimplikationen wirklich verstanden zu haben. Das Hauptproblem ist, dass viele Entwickler LLMs wie magische Blackboxen behandeln, ohne deren Grenzen zu verstehen. Bei klassischer Software kannst du den Code analysieren und Schwachstellen finden, aber bei LLMs ist das viel schwieriger.
Was mich ebenfalls wie Dennis besonders beunruhigt: Unternehmen geben KI-Systemen viel zu weitreichende Berechtigungen. Ein KI-Agent, der deine Mails lesen und beantworten kann, hat bereits enormes Schadenspotential, wenn er kompromittiert wird. Und je autonomer diese Systeme werden, desto schwieriger wird die Kontrolle.
Der einzige Weg zu mehr Sicherheit f√ºhrt √ºber ein grundlegendes Umdenken: Zero-Trust-Prinzipien auch f√ºr KI, minimale Berechtigungen, und vor allem ein realistisches Verst√§ndnis der Schwachstellen dieser Technologie. Die aktuellen Sicherheitsmechanismen sind noch in den Kinderschuhen - wir m√ºssen viel weiter denken.

**Smart Labs AI:** Kurz noch zu SCY Club, was steht dahinter?

**Dr. Thomas Fraunholz:** Die Smart Labs AI ist ja ein Spross der Smart Cyber Security GmbH und deren Abk√ºrzung war SCY und deswegen haben wir uns SCY Club genannt. Ein neuer Name wird noch entwickelt.

**Smart Labs AI:** Herzlichen Dank f√ºr das Interview und weiterhin viel Erfolg!
